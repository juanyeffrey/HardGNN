# ðŸš€ HardGNN for Google Colab Pro+

This folder contains a **standalone** implementation of HardGNN optimized for Google Colab Pro+ with GPU acceleration.

## ðŸ“‹ Quick Start Guide

### Step 1: Upload to Google Colab
1. **Upload this entire `Google-Colab` folder** to your Google Drive
2. **Open Google Colab**: https://colab.research.google.com/
3. **Mount Google Drive** in Colab:
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```
4. **Navigate to the folder**:
   ```python
   import os
   os.chdir('/content/drive/MyDrive/Google-Colab')  # Adjust path as needed
   ```

### Step 2: Configure Runtime
1. **Set GPU Runtime**: 
   - Runtime â†’ Change runtime type â†’ GPU (T4, A100, or V100)
   - For best performance: Use Colab Pro+ with A100 GPU

### Step 3: Create HardGNN Notebook
**ðŸ“ Important**: Instead of pre-made .ipynb files (which can have compatibility issues), use our **copy-paste approach**:

1. **Follow the detailed guide**: Open `Colab_Setup_Guide.md` for step-by-step instructions
2. **Use the script**: Open `HardGNN_Colab_Script.py` and copy sections into Colab cells
3. **Method 1 (Recommended)**: Copy each "CELL X" section into separate Colab cells
4. **Method 2 (Quick)**: Copy the entire script into one cell

### Step 4: Run HardGNN
The notebook will:
- Install dependencies automatically
- Load the Amazon dataset 
- Validate contrastive loss component
- Train HardGNN with hard negative sampling
- Compare with baseline SelfGNN

## ðŸ“Š What You'll See

### Training Output Example:
```
ðŸš€ Starting HardGNN Training...
ðŸ“Š Configuration: Ï„=0.1, K=5, Î»=0.1

Epoch 1/20
ðŸ‹ï¸  Train: Loss=0.8234, PreLoss=0.7845, ContrastiveLoss=0.3891
ðŸŽ¯ Test: HR=0.0856, NDCG=0.0423

Epoch 3/20  
ðŸ‹ï¸  Train: Loss=0.6721, PreLoss=0.6234, ContrastiveLoss=0.2876
ðŸŽ¯ Test: HR=0.1234, NDCG=0.0687
ðŸŒŸ New best NDCG: 0.0687

...

ðŸ“Š FINAL RESULTS
ðŸŽ¯ Final Test Results:
  HR@10: 0.1456
  NDCG@10: 0.0821

ðŸ† Best Results (Epoch 15):
  Best HR@10: 0.1523
  Best NDCG@10: 0.0834

âœ… HardGNN training completed successfully!
```

## ðŸ”§ Configuration Options

The script is pre-configured with your specified parameters:

```python
args.use_hard_neg = True          # Enable hard negative sampling
args.temp = 0.1                   # Temperature Ï„ for InfoNCE
args.hard_neg_top_k = 5           # Number of hard negatives K  
args.contrastive_weight = 0.1     # Contrastive loss weight Î»
args.data = 'amazon'              # Amazon-book dataset
```

### Adjustable Parameters:
- **Training epochs**: Modify `args.epoch` (default: 20 for Colab demo)
- **Batch size**: Modify `args.batch` (default: 512)
- **Learning rate**: Modify `args.lr` (default: 1e-3)
- **Test frequency**: Modify `args.tstEpoch` (default: 2)

## ðŸ“ Included Files

```
Google-Colab/
â”œâ”€â”€ HardGNN_Colab_Script.py     # Complete Python script for copy-paste
â”œâ”€â”€ Colab_Setup_Guide.md        # Detailed step-by-step setup guide
â”œâ”€â”€ model.py                    # HardGNN model implementation
â”œâ”€â”€ Params.py                   # Configuration parameters
â”œâ”€â”€ DataHandler.py              # Data loading utilities
â”œâ”€â”€ main.py                     # Training entry point
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Utils/                      # Utility modules
â”‚   â”œâ”€â”€ TimeLogger.py           # Logging utilities
â”‚   â”œâ”€â”€ NNLayers.py             # Neural network layers
â”‚   â””â”€â”€ attention.py            # Attention mechanisms
â”œâ”€â”€ Datasets/                   # Dataset directory
â”‚   â””â”€â”€ amazon/                 # Amazon-book dataset
â””â”€â”€ README.md                   # This file
```

## ðŸ› Troubleshooting

### Common Issues:

1. **GPU Memory Errors**:
   ```python
   # Reduce batch size
   args.batch = 256  # Instead of 512
   
   # Reduce training instances
   args.trnNum = 2000  # Instead of 5000
   ```

2. **Module Import Errors**:
   - Ensure you're in the correct directory: `os.chdir('/path/to/Google-Colab')`
   - Check that all files were uploaded correctly

3. **Dataset Loading Issues**:
   - The code includes fallback to dummy data if Amazon dataset is missing
   - For real experiments, ensure Amazon dataset is properly uploaded

4. **TensorFlow Version Issues**:
   - The script installs TF 1.14 for compatibility
   - If issues persist, restart runtime and re-run setup cells

### Performance Tips:

1. **Use Colab Pro+** with A100 GPU for best performance
2. **Monitor GPU usage**: Runtime â†’ View resources  
3. **Save checkpoints**: Uncomment `model.saveHistory()` if training long
4. **Reduce data size** for faster experimentation

## ðŸŽ¯ Expected Results

With the Amazon dataset and proper GPU setup, you should see:

- **Contrastive Loss**: Decreasing from ~0.4 to ~0.2 over epochs
- **HR@10**: Improving from ~0.08 to ~0.15+ 
- **NDCG@10**: Improving from ~0.04 to ~0.08+
- **HardGNN vs Baseline**: 5-15% improvement in NDCG@10

## ðŸ“š Understanding the Output

### Key Metrics:
- **ContrastiveLoss**: InfoNCE loss for hard negatives (lower = better)
- **HR@10**: Hit Ratio - fraction of test cases where true item is in top-10
- **NDCG@10**: Normalized Discounted Cumulative Gain - ranking quality metric
- **Prediction Gap**: Difference between positive and negative predictions

### Training Progress:
- Monitor decreasing contrastive loss âœ…
- Watch for improving HR and NDCG âœ…  
- Check that positive predictions > negative predictions âœ…

## ðŸ”¬ Research Extensions

Ready to experiment? Try:

1. **Parameter Tuning**:
   ```python
   args.temp = 0.05        # Lower temperature
   args.hard_neg_top_k = 10    # More hard negatives
   args.contrastive_weight = 0.2   # Higher contrastive weight
   ```

2. **Ablation Studies**:
   - Run with `args.use_hard_neg = False` to see baseline
   - Compare different temperature values
   - Test various K values for hard negatives

3. **Other Datasets**:
   ```python
   args.data = 'yelp'      # or 'movielens', 'gowalla'
   ```

## ðŸ“„ Citation

If you use this code in your research, please cite:

```bibtex
@article{liu2024selfgnn,
  title={SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation},
  author={Liu, Yuxi and Xia, Lianghao and Huang, Chao},
  journal={arXiv preprint arXiv:2405.20878},
  year={2024}
}
```

---

**Ready to run! ðŸš€** 

1. **Open** `Colab_Setup_Guide.md` for detailed instructions
2. **Copy** sections from `HardGNN_Colab_Script.py` into Colab cells
3. **Start** experimenting with hard negative sampling for sequential recommendation!

This approach ensures compatibility and gives you full control over the notebook creation process. 